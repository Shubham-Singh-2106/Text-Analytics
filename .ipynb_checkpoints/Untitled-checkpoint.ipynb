{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f8f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "corpus_tfidf_body = Sparse2Corpus(vectors_text.T)  # Convert TF-IDF vectors to gensim corpus format\n",
    "\n",
    "# Create a dictionary from the TF-IDF feature names\n",
    "dictionary = Dictionary.from_corpus(corpus_tfidf_body, id2word={i: feature_name for i, feature_name in enumerate(tfidf_text.get_feature_names_out())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a79d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "lda_model_tfidf_body = LdaModel(corpus_tfidf_body, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd36d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b94291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize the documents\n",
    "tokenized_documents = [word_tokenize(document) for document in filtered_df1['Body']]\n",
    "w_star_count = 0  # Initialize w_star_count with a default value\n",
    "\n",
    "co_occur_count = 10  # Example value, replace with your actual calculation\n",
    "num_docs = 100  # Example value, replace with your actual calculation\n",
    "EPSILON = 1e-9  # Example value, replace with your desired epsilon\n",
    "\n",
    "try:\n",
    "    if w_star_count == 0 or co_occur_count == 0:\n",
    "        m_lc_i = 0.0  # Set a default value or handle it as per your requirement\n",
    "    else:\n",
    "        numerator = (co_occur_count / num_docs) + EPSILON\n",
    "        denominator = w_star_count / num_docs\n",
    "        if denominator == 0:\n",
    "            m_lc_i = np.inf  # Handle division by zero by assigning infinity or a suitable value\n",
    "        else:\n",
    "            m_lc_i = np.log(numerator / denominator)\n",
    "except ZeroDivisionError:\n",
    "    print(\"Warning: Division by zero occurred. Setting m_lc_i to 0.0.\")\n",
    "    m_lc_i = 0.0\n",
    "\n",
    "try:\n",
    "    coherence_model_tfidf_body = CoherenceModel(model=lda_model_tfidf_body, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score_tfidf_body = coherence_model_tfidf_body.get_coherence()\n",
    "    print(\"Coherence Score - TF-IDF Body:\", coherence_score_tfidf_body)\n",
    "except Exception as e:\n",
    "    print(\"Error occurred during coherence calculation:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words=stopwords.words('english'), min_df=5, max_df=0.7)\n",
    "count_vectors = count_vectorizer.fit_transform(filtered_df1['Body'])\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_model = LatentDirichletAllocation(n_components = 10, random_state=42)\n",
    "W_lda_matrix = lda_model.fit_transform(count_vectors)\n",
    "H_lda_matrix = lda_model.components_\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_text = TfidfVectorizer(stop_words=stopwords.words('english'), min_df=5, max_df=0.7)\n",
    "vectors_text = tfidf_text.fit_transform(filtered_df1['Body'])\n",
    "vectors_text.shape\n",
    "\n",
    "def display_topics(model, features, no_top_words=10):\n",
    "    for topic, word_vector in enumerate(model.components_):\n",
    "        total = word_vector.sum()\n",
    "        largest = word_vector.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\" %s (%2.2f)\" % (features[largest[i]],word_vector[largest[i]]*100.0/total))\n",
    "            \n",
    "\n",
    "display_topics(lda_model, tfidf_text.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "\n",
    "# Tokenize the documents\n",
    "tokenized_documents = [word_tokenize(document) for document in filtered_df1['Body']]\n",
    "w_star_count = 0  # Initialize w_star_count with a default value\n",
    "\n",
    "co_occur_count = 10  # Example value, replace with your actual calculation\n",
    "num_docs = 100  # Example value, replace with your actual calculation\n",
    "EPSILON = 1e-9  # Example value, replace with your desired epsilon\n",
    "\n",
    "try:\n",
    "    if w_star_count == 0 or co_occur_count == 0:\n",
    "        m_lc_i = 0.0  # Set a default value or handle it as per your requirement\n",
    "    else:\n",
    "        numerator = (co_occur_count / num_docs) + EPSILON\n",
    "        denominator = w_star_count / num_docs\n",
    "        if denominator == 0:\n",
    "            m_lc_i = np.inf  # Handle division by zero by assigning infinity or a suitable value\n",
    "        else:\n",
    "            m_lc_i = np.log(numerator / denominator)\n",
    "except ZeroDivisionError:\n",
    "    print(\"Warning: Division by zero occurred. Setting m_lc_i to 0.0.\")\n",
    "    m_lc_i = 0.0\n",
    "\n",
    "try:\n",
    "    coherence_model_tfidf_body = CoherenceModel(model=lda_model_tfidf_body, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score_tfidf_body = coherence_model_tfidf_body.get_coherence()\n",
    "    print(\"Coherence Score - TF-IDF Body:\", coherence_score_tfidf_body)\n",
    "except Exception as e:\n",
    "    print(\"Error occurred during coherence calculation:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "\n",
    "lda_model_tfidf_body = LdaModel(corpus_tfidf_body, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd906b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb77bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "corpus_tfidf_body = Sparse2Corpus(vectors_text.T)  # Convert TF-IDF vectors to gensim corpus format\n",
    "\n",
    "# Create a dictionary from the TF-IDF feature names\n",
    "dictionary = Dictionary.from_corpus(corpus_tfidf_body, id2word={i: feature_name for i, feature_name in enumerate(tfidf_text.get_feature_names_out())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edbfd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c712191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106eeced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe440cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Create a list of documents from the 'Body' column\n",
    "documents_body = filtered_df1['Body'].tolist()\n",
    "\n",
    "# Create a list of documents from the 'Summary' column\n",
    "documents_summary = df['Summary'].tolist()\n",
    "\n",
    "# Combine the 'Body' and 'Summary' documents\n",
    "documents = documents_body + documents_summary\n",
    "\n",
    "# Tokenize the documents\n",
    "tokenized_documents = [doc.split() for doc in documents]\n",
    "\n",
    "# Create a dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(tokenized_documents)\n",
    "\n",
    "# Create the bag-of-words representation for 'Body'\n",
    "bow_corpus_body = [dictionary.doc2bow(doc.split()) for doc in documents_body]\n",
    "\n",
    "# Create the bag-of-words representation for 'Summary'\n",
    "bow_corpus_summary = [dictionary.doc2bow(doc.split()) for doc in documents_summary]\n",
    "\n",
    "num_topics = 10\n",
    "\n",
    "# Create the LDA model for 'Body' using the bag-of-words representation\n",
    "lda_model_body = LdaModel(bow_corpus_body, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Create the LDA model for 'Summary' using the bag-of-words representation\n",
    "lda_model_summary = LdaModel(bow_corpus_summary, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate the coherence score for 'Body'\n",
    "coherence_model_body = CoherenceModel(model=lda_model_body, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_body = coherence_model_body.get_coherence()\n",
    "\n",
    "# Calculate the coherence score for 'Summary'\n",
    "coherence_model_summary = CoherenceModel(model=lda_model_summary, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_summary = coherence_model_summary.get_coherence()\n",
    "\n",
    "print(\"Coherence Score - Body(TF-IDF):\", coherence_score_body)\n",
    "print(\"Coherence Score - Summary(TF-IDF):\", coherence_score_summary)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of topics to evaluate\n",
    "start_topic = 2\n",
    "end_topic = 10\n",
    "\n",
    "# Initialize lists to store coherence scores\n",
    "coherence_scores_body = []\n",
    "coherence_scores_summary = []\n",
    "\n",
    "# Define the number of topics\n",
    "num_topics = end_topic - start_topic + 1\n",
    "\n",
    "# Iterate over the range of topics\n",
    "for num_topics in range(start_topic, end_topic + 1):\n",
    "    # Create the LDA model for 'Body' using the bag-of-words representation\n",
    "    lda_model_body = LdaModel(bow_corpus_body, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "    # Create the LDA model for 'Summary' using the bag-of-words representation\n",
    "    lda_model_summary = LdaModel(bow_corpus_summary, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "    # Calculate the coherence score for 'Body'\n",
    "    coherence_model_body = CoherenceModel(model=lda_model_body, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score_body = coherence_model_body.get_coherence()\n",
    "\n",
    "    # Calculate the coherence score for 'Summary'\n",
    "    coherence_model_summary = CoherenceModel(model=lda_model_summary, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score_summary = coherence_model_summary.get_coherence()\n",
    "\n",
    "    # Append the coherence scores to the respective lists\n",
    "    coherence_scores_body\n",
    "    coherence_score_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Create a list of documents from the 'Body' column\n",
    "documents_body = filtered_df1['Body'].tolist()\n",
    "\n",
    "# Create a list of documents from the 'Summary' column\n",
    "documents_summary = df['Summary'].tolist()\n",
    "\n",
    "# Combine the 'Body' and 'Summary' documents\n",
    "documents = documents_body + documents_summary\n",
    "\n",
    "# Tokenize the documents\n",
    "tokenized_documents = [doc.split() for doc in documents]\n",
    "\n",
    "# Create a dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(tokenized_documents)\n",
    "\n",
    "# Create the bag-of-words representation for 'Body'\n",
    "bow_corpus_body = [dictionary.doc2bow(doc.split()) for doc in documents_body]\n",
    "\n",
    "# Create the bag-of-words representation for 'Summary'\n",
    "bow_corpus_summary = [dictionary.doc2bow(doc.split()) for doc in documents_summary]\n",
    "\n",
    "num_topics = 10\n",
    "\n",
    "# Create the LDA model for 'Body' using bag-of-words representation\n",
    "lda_model_body = LdaModel(bow_corpus_body, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Create the LDA model for 'Summary' using bag-of-words representation\n",
    "lda_model_summary = LdaModel(bow_corpus_summary, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate the coherence score for 'Body'\n",
    "coherence_model_body = CoherenceModel(model=lda_model_body, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_body = coherence_model_body.get_coherence()\n",
    "\n",
    "# Calculate the coherence score for 'Summary'\n",
    "coherence_model_summary = CoherenceModel(model=lda_model_summary, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_summary = coherence_model_summary.get_coherence()\n",
    "\n",
    "print(\"Coherence Score - Body(BoW):\", coherence_score_body)\n",
    "print(\"Coherence Score - Summary(BoW):\", coherence_score_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d759de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of topics to evaluate\n",
    "start_topic = 2\n",
    "end_topic = 10\n",
    "\n",
    "# Initialize lists to store coherence scores\n",
    "coherence_scores_body = []\n",
    "coherence_scores_summary = []\n",
    "\n",
    "# Define the number of topics\n",
    "num_topics = end_topic - start_topic + 1\n",
    "\n",
    "# Iterate over the range of topics\n",
    "for num_topics in range(start_topic, end_topic + 1):\n",
    "    # Create the LDA model for 'Body' using bag-of-words representation\n",
    "    lda_model_body = LdaModel(bow_corpus_body, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "    # Create the LDA model for 'Summary' using bag-of-words representation\n",
    "    lda_model_summary = LdaModel(bow_corpus_summary, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "    # Calculate the coherence score for 'Body'\n",
    "    coherence_model_body = CoherenceModel(model=lda_model_body, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score_body = coherence_model_body.get_coherence()\n",
    "\n",
    "    # Calculate the coherence score for 'Summary'\n",
    "    coherence_model_summary = CoherenceModel(model=lda_model_summary, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score_summary = coherence_model_summary.get_coherence()\n",
    "\n",
    "    # Append the coherence scores to the respective lists\n",
    "    coherence_scores_body.append(coherence_score_body)\n",
    "    coherence_scores_summary.append(coherence_score_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a4db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Create a list of documents from the 'Body' column\n",
    "documents_body = filtered_df1['Body'].tolist()\n",
    "\n",
    "# Create a list of documents from the 'Summary' column\n",
    "documents_summary = df['Summary'].tolist()\n",
    "\n",
    "# Combine the 'Body' and 'Summary' documents\n",
    "documents = documents_body + documents_summary\n",
    "\n",
    "# Tokenize the documents\n",
    "tokenized_documents = [doc.split() for doc in documents]\n",
    "\n",
    "# Create a dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(tokenized_documents)\n",
    "\n",
    "# Create the bag-of-words representation for 'Body'\n",
    "tfidf_corpus_body = [dictionary.doc2bow(doc.split()) for doc in documents_body]\n",
    "\n",
    "# Create the bag-of-words representation for 'Summary'\n",
    "tfidf_corpus_summary = [dictionary.doc2bow(doc.split()) for doc in documents_summary]\n",
    "\n",
    "# Create the LDA model for 'Body' using bag-of-words representation\n",
    "Tfidf_model_body = TfidfModel(tfidf_corpus_body)\n",
    "\n",
    "# Create the LDA model for 'Summary' using bag-of-words representation\n",
    "Tfidf_model_summary = TfidfModel(tfidf_corpus_summary)\n",
    "\n",
    "\n",
    "# Step 3: Train the LDA model\n",
    "num_topics = 10  # Choose the desired number of topics\n",
    "\n",
    "# Create the LDA model for 'Body' using bag-of-words representation\n",
    "lda_model_body = LdaModel(tfidf_corpus_body, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Create the LDA model for 'Summary' using bag-of-words representation\n",
    "lda_model_summary = LdaModel(tfidf_corpus_summary, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Step 4: Extract the topics\n",
    "topics = lda_model.show_topics()\n",
    "\n",
    "# Calculate the coherence score for 'Body'\n",
    "coherence_model_body = CoherenceModel(model=lda_model_body, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_body = coherence_model_body.get_coherence()\n",
    "\n",
    "# Calculate the coherence score for 'Summary'\n",
    "coherence_model_summary = CoherenceModel(model=lda_model_summary, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_summary = coherence_model_summary.get_coherence()\n",
    "\n",
    "print(\"Coherence Score - Body(Tfidf):\", coherence_score_body)\n",
    "print(\"Coherence Score - Summary(Tfidf):\", coherence_score_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10d693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b68a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Create a list of documents from the 'Body' column\n",
    "documents_body = filtered_df1['Body'].tolist()\n",
    "\n",
    "# Create a list of documents from the 'Summary' column\n",
    "documents_summary = df['Summary'].tolist()\n",
    "\n",
    "# Combine the 'Body' and 'Summary' documents\n",
    "documents = documents_body + documents_summary\n",
    "\n",
    "# Tokenize the documents\n",
    "tokenized_documents = [doc.split() for doc in documents]\n",
    "\n",
    "# Create a dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(tokenized_documents)\n",
    "\n",
    "# Create the bag-of-words representation for 'Body'\n",
    "bow_corpus_body = [dictionary.doc2bow(doc.split()) for doc in documents_body]\n",
    "\n",
    "# Create the bag-of-words representation for 'Summary'\n",
    "bow_corpus_summary = [dictionary.doc2bow(doc.split()) for doc in documents_summary]\n",
    "\n",
    "num_topics = 10\n",
    "\n",
    "# Create the LDA model for 'Body' using bag-of-words representation\n",
    "lda_model_body = LdaModel(bow_corpus_body, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Create the LDA model for 'Summary' using bag-of-words representation\n",
    "lda_model_summary = LdaModel(bow_corpus_summary, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate the coherence score for 'Body'\n",
    "coherence_model_body = CoherenceModel(model=lda_model_body, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_body = coherence_model_body.get_coherence()\n",
    "\n",
    "# Calculate the coherence score for 'Summary'\n",
    "coherence_model_summary = CoherenceModel(model=lda_model_summary, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_summary = coherence_model_summary.get_coherence()\n",
    "\n",
    "print(\"Coherence Score - Body(BoW):\", coherence_score_body)\n",
    "print(\"Coherence Score - Summary(BoW):\", coherence_score_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c0c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of topics to evaluate\n",
    "start_topic = 2\n",
    "end_topic = 10\n",
    "\n",
    "# Initialize lists to store coherence scores\n",
    "coherence_scores_body = []\n",
    "coherence_scores_summary = []\n",
    "\n",
    "# Define the number of topics\n",
    "num_topics = end_topic - start_topic + 1\n",
    "\n",
    "# Iterate over the range of topics\n",
    "for num_topics in range(start_topic, end_topic + 1):\n",
    "    # Create the LDA model for 'Body' using bag-of-words representation\n",
    "    lda_model_body = LdaModel(bow_corpus_body, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "    # Create the LDA model for 'Summary' using bag-of-words representation\n",
    "    lda_model_summary = LdaModel(bow_corpus_summary, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "    # Calculate the coherence score for 'Body'\n",
    "    coherence_model_body = CoherenceModel(model=lda_model_body, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score_body = coherence_model_body.get_coherence()\n",
    "\n",
    "    # Calculate the coherence score for 'Summary'\n",
    "    coherence_model_summary = CoherenceModel(model=lda_model_summary, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score_summary = coherence_model_summary.get_coherence()\n",
    "\n",
    "    # Append the coherence scores to the respective lists\n",
    "    coherence_scores_body.append(coherence_score_body)\n",
    "    coherence_scores_summary.append(coherence_score_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the coherence scores\n",
    "x = np.arange(start_topic, end_topic + 1)\n",
    "plt.plot(x, coherence_scores_body, marker='o', label='BoW Article')\n",
    "plt.plot(x, coherence_scores_summary, marker='o', label='BoW Summary')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.title('Coherence Score vs Number of Topics')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "d= plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8e870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Create a list of documents from the 'Body' column\n",
    "documents_body = filtered_df1['Body'].tolist()\n",
    "\n",
    "# Create a list of documents from the 'Summary' column\n",
    "documents_summary = df['Summary'].tolist()\n",
    "\n",
    "# Combine the 'Body' and 'Summary' documents\n",
    "documents = documents_body + documents_summary\n",
    "\n",
    "# Tokenize the documents\n",
    "tokenized_documents = [doc.split() for doc in documents]\n",
    "\n",
    "# Create a dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(tokenized_documents)\n",
    "\n",
    "# Create the bag-of-words representation for 'Body'\n",
    "tfidf_corpus_body = [dictionary.doc2bow(doc.split()) for doc in documents_body]\n",
    "\n",
    "# Create the bag-of-words representation for 'Summary'\n",
    "tfidf_corpus_summary = [dictionary.doc2bow(doc.split()) for doc in documents_summary]\n",
    "\n",
    "# Create the LDA model for 'Body' using bag-of-words representation\n",
    "Tfidf_model_body = TfidfModel(tfidf_corpus_body)\n",
    "\n",
    "# Create the LDA model for 'Summary' using bag-of-words representation\n",
    "Tfidf_model_summary = TfidfModel(tfidf_corpus_summary)\n",
    "\n",
    "\n",
    "# Step 3: Train the LDA model\n",
    "num_topics = 10  # Choose the desired number of topics\n",
    "\n",
    "# Create the LDA model for 'Body' using bag-of-words representation\n",
    "lda_model_body = LdaModel(tfidf_corpus_body, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Create the LDA model for 'Summary' using bag-of-words representation\n",
    "lda_model_summary = LdaModel(tfidf_corpus_summary, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate the coherence score for 'Body'\n",
    "coherence_model_body = CoherenceModel(model=lda_model_body, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_body = coherence_model_body.get_coherence()\n",
    "\n",
    "# Calculate the coherence score for 'Summary'\n",
    "coherence_model_summary = CoherenceModel(model=lda_model_summary, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_summary = coherence_model_summary.get_coherence()\n",
    "\n",
    "print(\"Coherence Score - Body(Tfidf):\", coherence_score_body)\n",
    "print(\"Coherence Score - Summary(Tfidf):\", coherence_score_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfe8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of topics to evaluate\n",
    "start_topic = 2\n",
    "end_topic = 10\n",
    "\n",
    "# Initialize lists to store coherence scores\n",
    "coherence_scores_body = []\n",
    "coherence_scores_summary = []\n",
    "\n",
    "# Define the number of topics\n",
    "num_topics = end_topic - start_topic + 1\n",
    "\n",
    "# Iterate over the range of topics\n",
    "for num_topics in range(start_topic, end_topic + 1):\n",
    "    # Create the LDA model for 'Body' using bag-of-words representation\n",
    "    lda_model_body = LdaModel(tfidf_corpus_body, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "    # Create the LDA model for 'Summary' using bag-of-words representation\n",
    "    lda_model_summary = LdaModel(tfidf_corpus_summary, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "    # Calculate the coherence score for 'Body'\n",
    "    coherence_model_body = CoherenceModel(model=lda_model_body, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score_body = coherence_model_body.get_coherence()\n",
    "\n",
    "    # Calculate the coherence score for 'Summary'\n",
    "    coherence_model_summary_Tfidf = CoherenceModel(model=lda_model_summary, texts=tokenized_documents, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score_summary_Tfidf = coherence_model_summary.get_coherence()\n",
    "\n",
    "    # Append the coherence scores to the respective lists\n",
    "    coherence_scores_body.append(coherence_score_body)\n",
    "    coherence_scores_summary.append(coherence_score_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the coherence scores\n",
    "x = np.arange(start_topic, end_topic + 1)\n",
    "plt.plot(x, coherence_scores_body, marker='o', label='TF-IDF Article')\n",
    "plt.plot(x, coherence_scores_summary, marker='o', label='TF-IDF Summary')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.title('Coherence Score vs Number of Topics')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "d= plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d9e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c584c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d43fb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62229bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507dc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbe769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db9d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1dd7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf17623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199205a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6567aa8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1444fd07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45eb0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ed500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd7030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c4a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3f297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd0b044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a572c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353026c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ddd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb48bf49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ae996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b78233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472d532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc8bb39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
